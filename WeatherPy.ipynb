{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import API key\n",
    "from api_key import weather_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporated citipy to determine city based on latitude and longitude\n",
    "from citipy import citipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output File (CSV)\n",
    "output_data_file = \"output_data/cities.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of latitudes and longitudes\n",
    "lat_range = (-90, 90)\n",
    "lat_range = (-180, 180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Cities List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of random lat and lng combinations\n",
    "lat_lngs = []\n",
    "\n",
    "lats = np.random.uniform(low=-90.000, high=90.000, size=30)\n",
    "lngs = np.random.uniform(low=-180.000, high=180.000, size=30)\n",
    "lat_lngs = zip(lats, lngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kavieng',\n",
       " 'general pico',\n",
       " 'saint george',\n",
       " 'ushuaia',\n",
       " 'codrington',\n",
       " 'san cristobal',\n",
       " 'busselton',\n",
       " 'margate',\n",
       " 'mataura',\n",
       " 'severo-kurilsk',\n",
       " 'lukulu',\n",
       " 'praia',\n",
       " 'faanui',\n",
       " 'hermanus',\n",
       " 'zaragoza',\n",
       " 'aloleng',\n",
       " 'padang',\n",
       " 'mountain home',\n",
       " 'snyder',\n",
       " 'katsuura',\n",
       " 'yeppoon',\n",
       " 'azimur',\n",
       " 'port alfred',\n",
       " 'ribeira grande',\n",
       " 'bandarbeyla',\n",
       " 'te anau',\n",
       " 'longyearbyen']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify nearest city for each lat, lng combination\n",
    "cities = []\n",
    "\n",
    "for lat_lng in lat_lngs:\n",
    "    city = citipy.nearest_city(lat_lng[0], lat_lng[1]).city_name\n",
    "    \n",
    "    # If the city is unique, then add it to our cities list\n",
    "    if city not in cities:\n",
    "         cities.append(city)            \n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "units = \"imperial\"\n",
    "query_url = f\"{url}appid={weather_api_key}&units={units}&q=\"\n",
    "# query_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Data Rerieval\n",
      "-----------------------\n",
      "Processing Record 1 of Set 1 | kavieng\n",
      "Processing Record 2 of Set 1 | general pico\n",
      "Processing Record 3 of Set 1 | saint george\n",
      "Processing Record 4 of Set 1 | ushuaia\n",
      "Processing Record 5 of Set 1 | codrington\n",
      "Processing Record 6 of Set 1 | san cristobal\n",
      "Processing Record 7 of Set 1 | busselton\n",
      "Processing Record 8 of Set 1 | margate\n",
      "Processing Record 9 of Set 1 | mataura\n",
      "Processing Record 10 of Set 1 | severo-kurilsk\n",
      "Processing Record 11 of Set 1 | lukulu\n",
      "Processing Record 12 of Set 1 | praia\n",
      "Processing Record 13 of Set 1 | faanui\n",
      "Processing Record 14 of Set 1 | hermanus\n",
      "Processing Record 15 of Set 1 | zaragoza\n",
      "Processing Record 16 of Set 1 | aloleng\n",
      "Processing Record 17 of Set 1 | padang\n",
      "Processing Record 18 of Set 1 | mountain home\n",
      "Processing Record 19 of Set 1 | snyder\n",
      "Processing Record 20 of Set 1 | katsuura\n",
      "Processing Record 21 of Set 1 | yeppoon\n",
      "city(azimur) not found\n",
      "Processing Record 23 of Set 2 | port alfred\n",
      "Processing Record 24 of Set 2 | ribeira grande\n",
      "Processing Record 25 of Set 2 | bandarbeyla\n",
      "Processing Record 26 of Set 2 | te anau\n",
      "Processing Record 27 of Set 2 | longyearbyen\n",
      "-----------------------\n",
      "Data Retrieval Complete\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "lat = []\n",
    "lon = []\n",
    "max_temp = []\n",
    "humidity = []\n",
    "cloudiness = []\n",
    "\n",
    "wind_speed = []\n",
    "date = []\n",
    "country = []\n",
    "city_name = []\n",
    "\n",
    "not_located = []\n",
    "except_set = 1\n",
    "\n",
    "print('Beginning Data Rerieval')\n",
    "print('-----------------------')\n",
    "\n",
    "for index, city in enumerate(cities, start=1):\n",
    "    try:\n",
    "        \n",
    "        response = requests.get(query_url + city).json()\n",
    "        # Request will be pause for 2 seconds   \n",
    "        time.sleep(2)\n",
    "        max_temp.append(response[\"main\"][\"temp_max\"])\n",
    "        humidity.append(response[\"main\"][\"humidity\"])\n",
    "        cloudiness.append(response[\"clouds\"][\"all\"])\n",
    "        \n",
    "        wind_speed.append(response[\"wind\"][\"speed\"])\n",
    "        date.append(response[\"dt\"])\n",
    "        country.append(response[\"sys\"][\"country\"])\n",
    "        lat.append(response[\"coord\"][\"lat\"])\n",
    "        lon.append(response[\"coord\"][\"lon\"])\n",
    "        city_name.append(city)\n",
    "        print(f'Processing Record {index} of Set {except_set} | {city}')\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        not_located.append(city)\n",
    "        print(f\"city({city}) not found\")\n",
    "        except_set+= 1\n",
    "print('-----------------------')\n",
    "print('Data Retrieval Complete')\n",
    "print('-----------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cities were found 26\n"
     ]
    }
   ],
   "source": [
    "found = len(cities)\n",
    "not_found = len(not_located)\n",
    "total_found = found - not_found\n",
    "print(f'Cities were found {total_found}')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataframe to store requests from those lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format the column of dates of the df\n",
    "dates = []\n",
    "for d in date:\n",
    "    date_test = d\n",
    "    date_conversion = time.gmtime(date_test)\n",
    "    date_format = time.strftime('%m/%d/%Y',date_conversion)\n",
    "    dates.append(date_format)\n",
    "# dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Output_Data/Cities.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-b4e0c6d67ad2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;34m\"date\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m })\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcities_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Output_Data/Cities.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3203\u001b[0m         )\n\u001b[1;32m-> 3204\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m             )\n\u001b[0;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Output_Data/Cities.csv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output_data/cities.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-ef98b636ea07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m }\n\u001b[0;32m     11\u001b[0m \u001b[0mweather_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweather_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mweather_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"output_data/cities.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mweather_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3203\u001b[0m         )\n\u001b[1;32m-> 3204\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m             )\n\u001b[0;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output_data/cities.csv'"
     ]
    }
   ],
   "source": [
    "# create a data frame from cities, lat, and temp\n",
    "weather_dict = {\n",
    "    \"city\": city_name,\n",
    "    \"lat\": lat,\n",
    "    \"max_temp\": max_temp,\n",
    "    \"humid\":humidity,\n",
    "    \"cloudiness\":cloudiness,\n",
    "    \"wind_speed\":wind_speed,\n",
    "    \"date\":dates\n",
    "}\n",
    "\n",
    "weather_data = pd.DataFrame(weather_dict)\n",
    "# weather_data.to_csv(\"output_data/cities.csv\", index = False)\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create scatter plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a scatter plot for each data type\n",
    "title_date = dates[0]\n",
    "plt.scatter(weather_data[\"lat\"], weather_data[\"max_temp\"], marker=\"o\")\n",
    "\n",
    "# Incorporate the other graph properties\n",
    "plt.title(f\"City Latitude vs. Temperature({title_date})\")\n",
    "plt.ylabel(\"Temperature (F)\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"TemperatureInWorldCities.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a scatter plot for each data type\n",
    "title_date = dates[0]\n",
    "plt.scatter(weather_data[\"lat\"], weather_data[\"humid\"], marker=\"o\")\n",
    "\n",
    "# Incorporate the other graph properties\n",
    "plt.title(\"City Latitude vs. Humidity({title_date})\")\n",
    "plt.ylabel(\"Humidity (%)\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"HumidityInWorldCities.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a scatter plot for each data type\n",
    "plt.scatter(weather_data[\"lat\"], weather_data[\"cloudiness\"], marker=\"o\")\n",
    "\n",
    "# Incorporate the other graph properties\n",
    "plt.title(\"City Latitude vs. Cloudiness (03/14/20)\")\n",
    "plt.ylabel(\"Cloudiness (%)\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"CloudinessInWorldCities.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build a scatter plot for each data type\n",
    "plt.scatter(weather_data[\"lat\"], weather_data[\"cloudiness\"], marker=\"o\")\n",
    "\n",
    "# Incorporate the other graph properties\n",
    "plt.title(\"City Latitude vs. wind_speed (03/14/20)\")\n",
    "plt.ylabel(\"wind_speed (mph)\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"WinSpeedInWorldCities.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norther Hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Northern Heisphere (Latitude > = 0)\n",
    "lat_range = (0, 90)\n",
    "lat_range = (-180, 180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use random function to generate random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of random lat and lng combinations\n",
    "lats = np.random.uniform(low=0, high=90.000, size=3)\n",
    "lngs = np.random.uniform(low=-180.000, high=180.000, size=3)\n",
    "\n",
    "# Format into one dataframe with lat and long in one row\n",
    "lat_lngs = zip(lats, lngs)\n",
    "# lat_lngs\n",
    "print_lat_lngs = list(lat_lngs) \n",
    "# print(f'{print_lat_lngs}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create query url and request data from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build query URL and request result\n",
    "responses = [];\n",
    "\n",
    "for lat_lng in print_lat_lngs:\n",
    "    query_url = f\"lat={lat_lng[0]}&lon={lat_lng[1]}&appid={weather_api_key}\"\n",
    "    cities_weather = requests.get(url+query_url).json()\n",
    "\n",
    "    # Request will be pause for 2 seconds   \n",
    "    time.sleep(2)\n",
    "    responses.append(cities_weather)\n",
    "    # Using json to print with readabel format\n",
    "    #print(json.dumps(responses, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Southern Hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Southern Hemisphere (Latitude <  0)\n",
    "lat_range = (-90, 0)\n",
    "lat_range = (-180, 180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use random function to generate random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of random lat and lng combinations\n",
    "lats = np.random.uniform(low=-90.000, high=0, size=3)\n",
    "lngs = np.random.uniform(low=-180.000, high=180.000, size=3)\n",
    "\n",
    "# Format into one dataframe with lat and long in one row\n",
    "lat_lngs = zip(lats, lngs)\n",
    "# lat_lngs\n",
    "print_lat_lngs = list(lat_lngs) \n",
    "print(f'{print_lat_lngs}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
